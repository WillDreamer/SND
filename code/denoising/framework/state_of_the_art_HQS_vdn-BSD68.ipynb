{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils import data as dat\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep prior - DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=17):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        features = 64\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(num_of_layers-2):\n",
    "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(features))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        out = self.dncnn(x)\n",
    "        return out\n",
    "    \n",
    "dncnn_s = DnCNN(channels=3, num_of_layers=17)\n",
    "device_ids = [0]\n",
    "dncnn_s = nn.DataParallel(dncnn_s, device_ids=device_ids).cuda()\n",
    "#--------------------------------------\n",
    "#Add the pretrained model to the path \n",
    "#--------------------------------------\n",
    "dncnn_s.load_state_dict(torch.load(os.path.join('checkpoints/dncnn_s25.pth')))\n",
    "dncnn_s.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep prior - VDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_chn, out_chn, bias=True):\n",
    "    layer = nn.Conv2d(in_chn, out_chn, kernel_size=3, stride=1, padding=1, bias=bias)\n",
    "    return layer\n",
    "class dncnn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dep=20, num_filters=64, slope=0.2):\n",
    "        '''\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            out_channels (int): number of output channels\n",
    "            dep (int): depth of the network, Default 20\n",
    "            num_filters (int): number of filters in each layer, Default 64\n",
    "        '''\n",
    "        super(dncnn, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, num_filters, bias=True)\n",
    "        self.relu = nn.LeakyReLU(slope, inplace=True)\n",
    "        mid_layer = []\n",
    "        for ii in range(1, dep-1):\n",
    "            mid_layer.append(conv3x3(num_filters, num_filters, bias=True))\n",
    "            mid_layer.append(nn.LeakyReLU(slope, inplace=True))\n",
    "        self.mid_layer = nn.Sequential(*mid_layer)\n",
    "        self.conv_last = conv3x3(num_filters, out_channels, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.mid_layer(x)\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=6, depth=4, wf=64, slope=0.2):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels, Default 3\n",
    "            depth (int): depth of the network, Default 4\n",
    "            wf (int): number of filters in the first layer, Default 32\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(UNetConvBlock(prev_channels, (2**i)*wf, slope))\n",
    "            prev_channels = (2**i) * wf\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, (2**i)*wf, slope))\n",
    "            prev_channels = (2**i)*wf\n",
    "\n",
    "        self.last = conv3x3(prev_channels, out_channels, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path)-1:\n",
    "                blocks.append(x)\n",
    "                x = F.avg_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i-1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, slope=0.2):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=1, bias=True))\n",
    "        block.append(nn.LeakyReLU(slope, inplace=True))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=1, bias=True))\n",
    "        block.append(nn.LeakyReLU(slope, inplace=True))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, slope=0.2):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2, bias=True)\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, slope)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def weight_init_kaiming(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if not m.bias is None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    return net\n",
    "\n",
    "class VDN(nn.Module):\n",
    "    def __init__(self, in_channels, wf=64, dep_S=5, dep_U=4, slope=0.2):\n",
    "        super(VDN, self).__init__()\n",
    "        net1 = UNet(in_channels, in_channels*2, wf=wf, depth=dep_U, slope=slope)\n",
    "        self.DNet = weight_init_kaiming(net1)\n",
    "        net2 = dncnn(in_channels, in_channels*2, dep=dep_S, num_filters=64, slope=slope)\n",
    "        self.SNet = weight_init_kaiming(net2)\n",
    "\n",
    "    def forward(self, x, mode='train'):\n",
    "        if mode.lower() == 'train':\n",
    "            phi_Z = self.DNet(x)\n",
    "            phi_sigma = self.SNet(x)\n",
    "            return phi_Z, phi_sigma\n",
    "        elif mode.lower() == 'test':\n",
    "            phi_Z = self.DNet(x)\n",
    "            return phi_Z\n",
    "        elif mode.lower() == 'sigma':\n",
    "            phi_sigma = self.SNet(x)\n",
    "            return phi_sigma\n",
    "#--------------------------------------\n",
    "#Add the pretrained model to the path \n",
    "#--------------------------------------\n",
    "checkpoint = torch.load('checkpoints/model_state_niidgauss')\n",
    "vdn = VDN(3, dep_U=4, wf=64)\n",
    "vdn = torch.nn.DataParallel(vdn).cuda()\n",
    "vdn.load_state_dict(checkpoint)\n",
    "vdn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Deep Priors Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model ...\\n')\n",
    "#----------------\n",
    "#Basic settings\n",
    "#----------------\n",
    "Plot = True\n",
    "psnr_test = 0\n",
    "ssim_test = 0\n",
    "sigma = 15\n",
    "test_data = 'data/BSD68/'\n",
    "iters = 2\n",
    "ii = 0\n",
    "start = time.time()\n",
    "#-----------------------------------------\n",
    "#Adaptive Deep Priors Framework on BSD68\n",
    "#-----------------------------------------\n",
    "for img in os.listdir(test_data):\n",
    "    ii+=1\n",
    "    print('Testing on the %dth pictures'%ii)\n",
    "    #--------------------------------------\n",
    "    #(1.1) Data augmentation of the input \n",
    "    #--------------------------------------\n",
    "    fname=test_data+'/'+img\n",
    "    img_pil = crop_image(Image.open(fname))\n",
    "    img_np = pil_to_np(img_pil)\n",
    "    if img_np.shape[1]>img_np.shape[2]:\n",
    "        out = img_pil.transpose(Image.ROTATE_90)\n",
    "        img_np = pil_to_np(out)\n",
    "    img_torch = np_to_torch(img_np).cuda()\n",
    "    gt_pil=crop_image(get_image(fname, -1)[0])\n",
    "    gt_np = pil_to_np(gt_pil)\n",
    "    if gt_np.shape[1]>gt_np.shape[2]:\n",
    "        out = gt_pil.transpose(Image.ROTATE_90)\n",
    "        gt_np = pil_to_np(out)\n",
    "    ISource = img_torch\n",
    "    #---------------------------------\n",
    "    #(1.2) Add the noise of the input\n",
    "    #---------------------------------\n",
    "    img_noisy_pil,img_noisy_np = get_noisy_image(gt_np,sigma/255.)\n",
    "    INoisy = np_to_torch(img_noisy_np)\n",
    "    ISource, INoisy = Variable(ISource.cuda()), Variable(INoisy.cuda())\n",
    "    img_noisy_np = torch_to_np(INoisy)\n",
    "    #--------------------------------------------------------\n",
    "    #(2) Initialization of the parameters\n",
    "    # You need to change the value for different conditions\n",
    "    #--------------------------------------------------------\n",
    "    yita = 0.6\n",
    "    delta =0.01\n",
    "    lam = 1 - delta*(1 + yita)\n",
    "    rou = 0.00001\n",
    "    A_ = np.eye(gt_np.shape[1])*lam #shape: [a,a]\n",
    "    A_T = np.eye(gt_np.shape[1]) # shape: [a,a]\n",
    "    A = A_T\n",
    "    y = torch_to_np(INoisy) #shape: [3,a,b]\n",
    "    v_0 = np.zeros(gt_np.shape) #shape [3,a,b]\n",
    "    x_0 = np.zeros(gt_np.shape) #shape [3,a,b]\n",
    "    for i in range(y.shape[0]):   \n",
    "        y_ = np.squeeze(y[i,:,:]) \n",
    "        x_0[i,:,:] = np.dot(A_T,y_)\n",
    "    x_next = x_0  #shape [3,a,b]        \n",
    "    v_next = v_0  #shape [3,a,b]\n",
    "    space=np.zeros(gt_np.shape) #shape [3,a,b]\n",
    "\n",
    "    with torch.no_grad(): # this can save much memory\n",
    "        #--------------------------------------\n",
    "        #(3) The main loop of our framework\n",
    "        #--------------------------------------\n",
    "        for i in range(iters):\n",
    "            #-----------------------------------------------\n",
    "            #(3.1) The forward model with gradient descent\n",
    "            #-----------------------------------------------\n",
    "            for i in range(x_next.shape[0]):\n",
    "                x_next_ = x_next[i,:,:]\n",
    "                y_ = y[i,:,:]\n",
    "                v_next_ = v_next[i,:,:]\n",
    "                x_next[i,:,:] = A_.dot(x_next_) + delta * A_T.dot(y_) + delta *v_next_ \n",
    "            x_next = np_to_torch(x_next).cuda().float()\n",
    "            #-----------------------------------------\n",
    "            #(3.2) Plug the deep prior\n",
    "            #-----------------------------------------\n",
    "            phi_Z = vdn(x_next, 'test')\n",
    "            err = phi_Z.cpu().numpy()\n",
    "            im_noisy = x_next.cpu().numpy()\n",
    "            #-----------------------------------------\n",
    "            #(3.3) Denoising\n",
    "            #-----------------------------------------\n",
    "            im_denoise = im_noisy - err[:, :3,]\n",
    "            im_denoise = im_denoise.squeeze()\n",
    "            v_next = np_to_torch(im_denoise).cuda()\n",
    "\n",
    "            x_next = torch_to_np(x_next)\n",
    "            v_next = torch_to_np(v_next)  \n",
    "            #-----------------------------------------\n",
    "            #(3.4) Update A for overcoming the blurriness\n",
    "            #-----------------------------------------\n",
    "            for j in range(x_next.shape[0]):\n",
    "                A_temp =  torch_to_np(INoisy - dncnn_s(INoisy))[j,:,:]#shape [3,a,b]\n",
    "                x_temp =  ((v_next[j,:,:].T).dot(A)).dot(v_next[j,:,:])[:gt_np.shape[1],:]#\n",
    "                space[j,:,:] = rou*(A_temp+x_temp)\n",
    "            t =  ((space[0,:,:]+space[1,:,:]+space[2,:,:])/3)[:gt_np.shape[1],:gt_np.shape[1]]\n",
    "            A = (A -t)[:gt_np.shape[1],:gt_np.shape[1]]\n",
    "            A_T = A.T        \n",
    "    v_next =pil_to_np(np_to_pil(v_next).convert('L'))\n",
    "    v_hat = np_to_torch(v_next) \n",
    "    Out = torch.clamp(v_hat,0.,1.)\n",
    "    stop = time.time() - start\n",
    "    out_img = torch_to_np(Out)\n",
    "    \n",
    "    if Plot:\n",
    "        plot_image_grid([np.clip(out_img, 0, 1),\n",
    "                         np.clip(img_noisy_np, 0, 1),np.clip(img_np, 0, 1)], factor=20, nrow=3)\n",
    "\n",
    "    psnr = batch_PSNR(Out, ISource,1.)\n",
    "    ssim = batch_SSIM(Out,ISource)\n",
    "    psnr_test += psnr\n",
    "    ssim_test += ssim\n",
    "    print('Time consumes %.3f s'%stop)\n",
    "    print(\"PSNR is: %f SSIM is: %f\" % (psnr,ssim))\n",
    "psnr_test /= len(os.listdir(test_data))\n",
    "print(\"\\nAverage PSNR on test data is: %f\" % psnr_test)\n",
    "ssim_test /= len(os.listdir(test_data))\n",
    "print(\"\\nAverage SSIM on test data is: %f\" % ssim_test)\n",
    "end = time.time() - start\n",
    "if not Plot:\n",
    "    ave_time = end/len(os.listdir(test_data))\n",
    "    print(\"\\nAverage Time on test data is: %f\" % ave_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
